# src/rag.py
"""
RAG (Retrieval-Augmented Generation) System

Bu modÃ¼l OpenWeatherMap API dÃ¶kÃ¼manlarÄ±nÄ±:
1. Okur ve parÃ§alara bÃ¶ler (chunking)
2. OpenAI ile embedding'lere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
3. MongoDB Atlas'a vector olarak kaydeder
4. Semantic search ile ilgili dÃ¶kÃ¼manlarÄ± bulur

LangSmith ile tÃ¼m iÅŸlemler otomatik trace edilir.
"""

import os
from typing import List
import dotenv

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores.mongodb_atlas import MongoDBAtlasVectorSearch
from langchain_core.documents import Document

from pymongo import MongoClient

# Environment variables yÃ¼kle
dotenv.load_dotenv()


class RAGSystem:
    """
    Retrieval-Augmented Generation sistemi

    Attributes:
        client: MongoDB client baÄŸlantÄ±sÄ±
        db: MongoDB database
        collection: MongoDB collection (documents)
        embeddings: OpenAI embeddings modeli
        vectorstore: MongoDB vector store
    """

    def __init__(self):
        """
        RAG sistemini baÅŸlat
        - MongoDB baÄŸlantÄ±sÄ±
        - OpenAI embeddings
        - Vector store
        """
        print("\nğŸš€ RAG System baÅŸlatÄ±lÄ±yor...")

        # ====================================================================
        # MongoDB Connection
        # ====================================================================
        mongodb_uri = os.getenv("MONGODB_URI")
        if not mongodb_uri:
            raise ValueError(
                "âŒ MONGODB_URI environment variable tanÄ±mlÄ± deÄŸil!\n"
                "   .env dosyasÄ±nÄ± kontrol edin."
            )

        try:
            self.client = MongoClient(mongodb_uri)
            self.db = self.client["weather_assistant"]
            self.collection = self.db["documents"]

            # Connection test
            self.client.server_info()
            print("âœ… MongoDB baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±")

        except Exception as e:
            raise ConnectionError(f"âŒ MongoDB baÄŸlantÄ± hatasÄ±: {e}")

        # ====================================================================
        # OpenAI Embeddings
        # ====================================================================
        openai_key = os.getenv("OPENAI_API_KEY")
        if not openai_key:
            raise ValueError(
                "âŒ OPENAI_API_KEY environment variable tanÄ±mlÄ± deÄŸil!\n"
                "   .env dosyasÄ±nÄ± kontrol edin."
            )

        try:
            self.embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small",  # 1536 dimensions
                openai_api_key=openai_key
            )
            print("âœ… OpenAI Embeddings modeli yÃ¼klendi")

        except Exception as e:
            raise ValueError(f"âŒ OpenAI Embeddings hatasÄ±: {e}")

        # ====================================================================
        # MongoDB Atlas Vector Search
        # ====================================================================
        try:
            self.vectorstore = MongoDBAtlasVectorSearch(
                collection=self.collection,
                embedding=self.embeddings,
                index_name="vector_index",  # Atlas'ta oluÅŸturduÄŸumuz index
                embedding_key="embedding",  # Embedding field adÄ±
                text_key="text"  # Text field adÄ±
            )
            print("âœ… Vector Store hazÄ±r")

        except Exception as e:
            raise ValueError(f"âŒ Vector Store hatasÄ±: {e}")

        print("ğŸ‰ RAG System baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!\n")

    def load_documents(
            self,
            file_path: str = "/Users/code23-1/PycharmProjects/ai-weather-assistant /data/docs/openweather_api_docs.txt",
            chunk_size: int = 800,
            chunk_overlap: int = 100
    ) -> int:
        """
        DÃ¶kÃ¼manlarÄ± yÃ¼kle, parÃ§ala ve MongoDB'ye kaydet

        Args:
            file_path: DÃ¶kÃ¼man dosya yolu
            chunk_size: Her chunk'Ä±n maksimum karakter sayÄ±sÄ±
            chunk_overlap: Chunk'lar arasÄ± Ã¶rtÃ¼ÅŸme (karakter)

        Returns:
            Eklenen chunk sayÄ±sÄ±

        Raises:
            FileNotFoundError: Dosya bulunamazsa
            Exception: DiÄŸer hatalar
        """
        print(f"\nğŸ“¥ DÃ¶kÃ¼manlar yÃ¼kleniyor: {file_path}")
        print("-" * 70)

        # ====================================================================
        # DosyayÄ± Oku
        # ====================================================================
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read()

            print(f"âœ… Dosya okundu: {len(text):,} karakter")

        except FileNotFoundError:
            raise FileNotFoundError(
                f"âŒ Dosya bulunamadÄ±: {file_path}\n"
                f"   LÃ¼tfen dÃ¶kÃ¼man dosyasÄ±nÄ± oluÅŸturun."
            )
        except Exception as e:
            raise Exception(f"âŒ Dosya okuma hatasÄ±: {e}")

        # ====================================================================
        # Text Splitting (Chunking)
        # ====================================================================
        print(f"\nâœ‚ï¸  Metin parÃ§alanÄ±yor...")
        print(f"   Chunk Size: {chunk_size}")
        print(f"   Chunk Overlap: {chunk_overlap}")

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=[
                "\n\n",  # Ã–nce paragraflardan bÃ¶l
                "\n",  # Sonra satÄ±rlardan
                " ",  # Sonra kelimelerden
                ""  # En son karakterlerden
            ],
            keep_separator=True
        )

        # Document oluÅŸtur
        doc = Document(
            page_content=text,
            metadata={
                "source": file_path,
                "type": "api_documentation",
                "total_chars": len(text)
            }
        )

        # ParÃ§ala
        chunks = text_splitter.split_documents([doc])

        print(f"âœ… {len(chunks)} parÃ§aya bÃ¶lÃ¼ndÃ¼")

        # Chunk bilgileri
        avg_chunk_size = sum(len(c.page_content) for c in chunks) / len(chunks)
        print(f"   Ortalama chunk boyutu: {avg_chunk_size:.0f} karakter")

        # ====================================================================
        # MongoDB'ye Ekle (Embedding otomatik oluÅŸur)
        # ====================================================================
        print(f"\nğŸ’¾ MongoDB'ye kaydediliyor...")

        try:
            # Her chunk iÃ§in metadata ekle
            for i, chunk in enumerate(chunks):
                chunk.metadata.update({
                    "chunk_id": i,
                    "chunk_size": len(chunk.page_content)
                })

            # Vector store'a ekle (embedding'ler otomatik oluÅŸur)
            ids = self.vectorstore.add_documents(chunks)

            print(f"âœ… {len(ids)} dÃ¶kÃ¼man MongoDB'ye eklendi")
            print(f"   Vector Index: vector_index")
            print(f"   Embedding Boyutu: 1536 (text-embedding-3-small)")

            return len(ids)

        except Exception as e:
            raise Exception(f"âŒ MongoDB kayÄ±t hatasÄ±: {e}")

    def search(
            self,
            query: str,
            k: int = 3,
            score_threshold: float = 0.7
    ) -> List[Document]:
        """
        Sorguya semantically benzer dÃ¶kÃ¼manlarÄ± ara

        Args:
            query: Arama sorgusu
            k: DÃ¶ndÃ¼rÃ¼lecek dÃ¶kÃ¼man sayÄ±sÄ±
            score_threshold: Minimum benzerlik skoru (0-1)

        Returns:
            List of Document objects with similarity scores
        """
        print(f"\nğŸ” Arama yapÄ±lÄ±yor: '{query}'")
        print(f"   Top-K: {k}")
        print(f"   Score Threshold: {score_threshold}")

        try:
            # Similarity search with scores
            docs_with_scores = self.vectorstore.similarity_search_with_score(
                query,
                k=k
            )

            # Filter by score threshold
            filtered_docs = [
                (doc, score)
                for doc, score in docs_with_scores
                if score >= score_threshold
            ]

            print(f"âœ… {len(filtered_docs)} sonuÃ§ bulundu")

            # Sadece document'leri dÃ¶ndÃ¼r (score'larÄ± metadata'ya ekle)
            results = []
            for doc, score in filtered_docs:
                doc.metadata["similarity_score"] = score
                results.append(doc)
                print(f"   ğŸ“„ Score: {score:.3f} | {doc.page_content[:60]}...")

            return results

        except Exception as e:
            print(f"âŒ Arama hatasÄ±: {e}")
            return []

    def get_context_for_query(
            self,
            query: str,
            k: int = 3,
            max_chars: int = 2000
    ) -> str:
        """
        Sorgu iÃ§in context metni oluÅŸtur (LLM'e gÃ¶nderilecek)

        Args:
            query: Arama sorgusu
            k: KullanÄ±lacak dÃ¶kÃ¼man sayÄ±sÄ±
            max_chars: Maksimum karakter sayÄ±sÄ±

        Returns:
            BirleÅŸtirilmiÅŸ context metni
        """
        docs = self.search(query, k=k)

        if not docs:
            return "Ä°lgili dÃ¶kÃ¼man bulunamadÄ±."

        # DÃ¶kÃ¼manlarÄ± birleÅŸtir
        context_parts = []
        total_chars = 0

        for i, doc in enumerate(docs, 1):
            doc_text = doc.page_content

            # Max char limit kontrolÃ¼
            if total_chars + len(doc_text) > max_chars:
                remaining = max_chars - total_chars
                doc_text = doc_text[:remaining] + "..."
                context_parts.append(f"[DÃ¶kÃ¼man {i}]\n{doc_text}")
                break

            context_parts.append(f"[DÃ¶kÃ¼man {i}]\n{doc_text}")
            total_chars += len(doc_text)

        context = "\n\n---\n\n".join(context_parts)

        print(f"ğŸ“ Context oluÅŸturuldu: {len(context)} karakter")

        return context

    def get_collection_stats(self) -> dict:
        """MongoDB collection istatistiklerini dÃ¶ndÃ¼r"""
        doc_count = self.collection.count_documents({})

        # Sample document al
        sample_doc = self.collection.find_one({})

        return {
            "total_documents": doc_count,
            "has_embeddings": bool(sample_doc and "embedding" in sample_doc),
            "embedding_size": len(sample_doc.get("embedding", [])) if sample_doc else 0
        }

    def clear_collection(self):
        """
        Collection'Ä± temizle (test iÃ§in)

        âš ï¸ DÄ°KKAT: TÃ¼m dÃ¶kÃ¼manlarÄ± siler!
        """
        result = self.collection.delete_many({})
        print(f"ğŸ—‘ï¸  {result.deleted_count} dÃ¶kÃ¼man silindi")


# ============================================================================
# Test ve Demo Fonksiyonu
# ============================================================================

def main():
    """RAG sistemini test et ve demo yap"""

    print("=" * 70)
    print(" RAG SYSTEM - TEST VE DEMO")
    print("=" * 70)

    # ====================================================================
    # RAG System OluÅŸtur
    # ====================================================================
    try:
        rag = RAGSystem()
    except Exception as e:
        print(f"\nâŒ RAG System oluÅŸturulamadÄ±: {e}")
        return

    # ====================================================================
    # Collection Ä°statistikleri
    # ====================================================================
    print("\n" + "=" * 70)
    print(" MONGODB COLLECTION Ä°STATÄ°STÄ°KLERÄ°")
    print("=" * 70)

    stats = rag.get_collection_stats()
    print(f"ğŸ“Š Toplam DÃ¶kÃ¼man: {stats['total_documents']}")
    print(f"ğŸ”¢ Embedding Var mÄ±: {stats['has_embeddings']}")
    print(f"ğŸ“ Embedding Boyutu: {stats['embedding_size']}")

    # ====================================================================
    # DÃ¶kÃ¼man YÃ¼kleme (EÄŸer collection boÅŸsa)
    # ====================================================================
    if stats['total_documents'] == 0:
        print("\n" + "=" * 70)
        print(" DÃ–KÃœMAN YÃœKLEME")
        print("=" * 70)

        try:
            chunk_count = rag.load_documents(
                file_path="data/docs/openweather_api_docs.txt",
                chunk_size=800,
                chunk_overlap=100
            )
            print(f"\nâœ… {chunk_count} dÃ¶kÃ¼man chunk'Ä± baÅŸarÄ±yla yÃ¼klendi!")
        except Exception as e:
            print(f"\nâŒ DÃ¶kÃ¼man yÃ¼kleme hatasÄ±: {e}")
            print("   data/docs/openweather_api_docs.txt dosyasÄ±nÄ±n var olduÄŸundan emin ol")
            return
    else:
        print(f"\nâœ… DÃ¶kÃ¼manlar zaten yÃ¼klenmiÅŸ (Toplam: {stats['total_documents']})")
        print("   Yeniden yÃ¼klemek iÃ§in Ã¶nce rag.clear_collection() Ã§alÄ±ÅŸtÄ±r")

    # ====================================================================
    # Test SorgularÄ±
    # ====================================================================
    print("\n" + "=" * 70)
    print(" TEST SORGULARI")
    print("=" * 70)

    test_queries = [
        {
            "query": "How do I get an API key?",
            "description": "API key alma sÃ¼reci"
        },
        {
            "query": "What is the endpoint for current weather?",
            "description": "Current weather endpoint"
        },
        {
            "query": "What units can I use for temperature?",
            "description": "SÄ±caklÄ±k birimleri"
        },
        {
            "query": "How to handle 401 error?",
            "description": "Hata yÃ¶netimi"
        },
        {
            "query": "API key nasÄ±l alÄ±nÄ±r?",
            "description": "TÃ¼rkÃ§e sorgu testi"
        }
    ]

    for i, test in enumerate(test_queries, 1):
        print(f"\n{'â”€' * 70}")
        print(f"Test {i}: {test['description']}")
        print(f"{'â”€' * 70}")
        print(f"â“ Sorgu: {test['query']}")

        # Arama yap
        docs = rag.search(test['query'], k=2, score_threshold=0.6)

        if docs:
            for j, doc in enumerate(docs, 1):
                score = doc.metadata.get('similarity_score', 0)
                print(f"\nğŸ“„ SonuÃ§ {j} (Score: {score:.3f})")
                print("â”€" * 70)
                # Ä°lk 300 karakteri gÃ¶ster
                content = doc.page_content[:300]
                print(content)
                if len(doc.page_content) > 300:
                    print("...")
        else:
            print("âŒ Ä°lgili dÃ¶kÃ¼man bulunamadÄ±")

    # ====================================================================
    # Context OluÅŸturma Demo
    # ====================================================================
    print("\n" + "=" * 70)
    print(" CONTEXT OLUÅTURMA DEMO")
    print("=" * 70)

    demo_query = "API key nereden alÄ±nÄ±r ve nasÄ±l kullanÄ±lÄ±r?"
    print(f"\nâ“ Sorgu: {demo_query}")

    context = rag.get_context_for_query(
        query=demo_query,
        k=3,
        max_chars=1500
    )

    print("\nğŸ“ OluÅŸturulan Context:")
    print("â”€" * 70)
    print(context)

    # ====================================================================
    # Ã–zet
    # ====================================================================
    print("\n" + "=" * 70)
    print(" TEST TAMAMLANDI")
    print("=" * 70)
    print("âœ… RAG sistemi baÅŸarÄ±yla Ã§alÄ±ÅŸÄ±yor!")
    print("âœ… DÃ¶kÃ¼manlar MongoDB'de")
    print("âœ… Semantic search Ã§alÄ±ÅŸÄ±yor")
    print("âœ… Context oluÅŸturma hazÄ±r")
    print("\nğŸ’¡ Bir sonraki adÄ±m: Weather API tool'u oluÅŸtur")
    print("=" * 70)


if __name__ == "__main__":
    main()